{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas&statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:47:07.554800Z",
     "start_time": "2018-12-04T01:46:57.728800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa   prestige\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "binary=pd.read_csv('E:\\\\binary.csv')            #读取数据\n",
    "binary.rename(columns={'rank':'prestige'}, inplace = True)      #重命名\n",
    "binary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:47:58.354800Z",
     "start_time": "2018-12-04T01:47:57.592800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x0000000009169550>]]\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x00000000091A9710>]]\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x00000000091F19E8>]]\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x0000000009237CC0>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in binary.columns:\n",
    "    print(binary.hist(i))                #hist方法简单方便"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:46.857000Z",
     "start_time": "2018-12-03T05:06:46.835000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit         0.3175\n",
       "gre         587.7000\n",
       "gpa           3.3899\n",
       "prestige      2.4850\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:06:51.074000Z",
     "start_time": "2018-12-03T05:06:49.059000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige   1   2   3   4\n",
       "admit                   \n",
       "0         28  97  93  55\n",
       "1         33  54  28  12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(binary.iloc[:,[0,3]],index='admit',columns='prestige',aggfunc=len)  #交叉表\n",
    "# binary.pivot_table(index=['admit'], columns='prestige', aggfunc=len, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:11:16.733800Z",
     "start_time": "2018-12-04T02:11:16.503800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>intercept</th>\n",
       "      <th>pre1</th>\n",
       "      <th>pre2</th>\n",
       "      <th>pre3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740</td>\n",
       "      <td>3.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  intercept  pre1  pre2  pre3\n",
       "0        0  380  3.61          1     0     0     0\n",
       "1        1  660  3.67          1     0     0     0\n",
       "2        1  800  4.00          1     0     1     0\n",
       "3        1  640  3.19          1     0     0     0\n",
       "4        0  520  2.93          1     0     0     0\n",
       "5        1  760  3.00          1     1     0     0\n",
       "6        1  560  2.98          1     0     1     0\n",
       "7        0  400  3.08          1     1     0     0\n",
       "8        1  540  3.39          1     0     0     0\n",
       "9        0  700  3.92          1     1     0     0\n",
       "10       0  800  4.00          1     0     0     0\n",
       "11       0  440  3.22          1     0     1     0\n",
       "12       1  760  4.00          1     0     1     0\n",
       "13       0  700  3.08          1     1     0     0\n",
       "14       1  700  4.00          1     0     1     0\n",
       "15       0  480  3.44          1     0     0     0\n",
       "16       0  780  3.87          1     0     0     0\n",
       "17       0  360  2.56          1     0     0     0\n",
       "18       0  800  3.75          1     1     0     0\n",
       "19       1  540  3.81          1     0     1     0\n",
       "20       0  500  3.17          1     0     0     0\n",
       "21       1  660  3.63          1     1     0     0\n",
       "22       0  600  2.82          1     0     0     0\n",
       "23       0  680  3.19          1     0     0     0\n",
       "24       1  760  3.35          1     1     0     0\n",
       "25       1  800  3.66          1     0     1     0\n",
       "26       1  620  3.61          1     0     1     0\n",
       "27       1  520  3.74          1     0     0     0\n",
       "28       1  780  3.22          1     1     0     0\n",
       "29       0  520  3.29          1     0     1     0\n",
       "..     ...  ...   ...        ...   ...   ...   ...\n",
       "370      1  540  3.77          1     1     0     0\n",
       "371      1  680  3.76          1     0     0     0\n",
       "372      1  680  2.42          1     0     1     0\n",
       "373      1  620  3.37          1     0     1     0\n",
       "374      0  560  3.78          1     1     0     0\n",
       "375      0  560  3.49          1     0     0     0\n",
       "376      0  620  3.63          1     1     0     0\n",
       "377      1  800  4.00          1     1     0     0\n",
       "378      0  640  3.12          1     0     0     0\n",
       "379      0  540  2.70          1     1     0     0\n",
       "380      0  700  3.65          1     1     0     0\n",
       "381      1  540  3.49          1     1     0     0\n",
       "382      0  540  3.51          1     1     0     0\n",
       "383      0  660  4.00          1     0     1     0\n",
       "384      1  480  2.62          1     1     0     0\n",
       "385      0  420  3.02          1     0     1     0\n",
       "386      1  740  3.86          1     1     0     0\n",
       "387      0  580  3.36          1     1     0     0\n",
       "388      0  640  3.17          1     1     0     0\n",
       "389      0  640  3.51          1     1     0     0\n",
       "390      1  800  3.05          1     1     0     0\n",
       "391      1  660  3.88          1     1     0     0\n",
       "392      1  600  3.38          1     0     0     0\n",
       "393      1  620  3.75          1     1     0     0\n",
       "394      1  460  3.99          1     0     0     0\n",
       "395      0  620  4.00          1     1     0     0\n",
       "396      0  560  3.04          1     0     0     0\n",
       "397      0  460  2.63          1     1     0     0\n",
       "398      0  700  3.65          1     1     0     0\n",
       "399      0  600  3.89          1     0     0     0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ['pre1','pre2','pre3']:             #设置三个虚拟变量\n",
    "    binary[i]=0\n",
    "for i in range(len(binary.index)):\n",
    "    if binary.iloc[i,3]==1:\n",
    "        binary.iloc[i,6]=1\n",
    "        \n",
    "    if binary.iloc[i,3]==2:\n",
    "        binary.iloc[i,5]=1\n",
    "\n",
    "    if binary.iloc[i,3]==3:\n",
    "        binary.iloc[i,4]=1\n",
    "binary.drop('prestige',axis=1,inplace=True)\n",
    "binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拟合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:05:32.005800Z",
     "start_time": "2018-12-04T02:05:18.441800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574302\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                          Logit   Df Residuals:                      396\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 04 Dec 2018   Pseudo R-squ.:                 0.08107\n",
      "Time:                        10:05:31   Log-Likelihood:                -229.72\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "                                        LLR p-value:                 8.207e-09\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "gre            0.0023      0.001      2.101      0.036       0.000       0.004\n",
      "gpa            0.7770      0.327      2.373      0.018       0.135       1.419\n",
      "prestige      -0.5600      0.127     -4.405      0.000      -0.809      -0.311\n",
      "intercept     -3.4495      1.133     -3.045      0.002      -5.670      -1.229\n",
      "============================================================================== gre          0.002294\n",
      "gpa          0.777014\n",
      "prestige    -0.560031\n",
      "intercept   -3.449548\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm    #调用statsmodels里面的api，通过api调用相当于调用了statsmodels.regression.linear_model，可以使用linear_model文件里的函数\n",
    "binary['intercept']=1\n",
    "spector_data = sm.datasets.spector.load()  #读取样例的数据集\n",
    "spector_data.exog = sm.add_constant(binary['intercept'], prepend=False)\n",
    "# Fit and summarize OLS model\n",
    "x = sm.add_constant(binary['intercept'])\n",
    "cols=binary.columns[1:]\n",
    "mod = sm.Logit(binary['admit'],binary[cols])\n",
    "res = mod.fit()\n",
    "print(res.summary(),res.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:06:32.845800Z",
     "start_time": "2018-12-04T02:06:32.822800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 49, Hit: 29, Precision: 59.18\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "cop = copy.deepcopy(binary)\n",
    "cop['intercept'] = 1.0\n",
    "cop['predict'] = res.predict(cop[cop.columns[1:]])\n",
    "total = 0\n",
    "hit = 0\n",
    "for value in cop.values:\n",
    "  # 预测分数 predict, 是数据中的最后一列\n",
    "  predict = value[-1]\n",
    "  # 实际录取结果\n",
    "  admit = int(value[0])\n",
    " \n",
    "  # 假定预测概率大于0.5则表示预测被录取\n",
    "  if predict > 0.5:\n",
    "    total += 1\n",
    "    if admit == 1:\n",
    "      hit += 1\n",
    "\n",
    "print ('Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:12:23.914800Z",
     "start_time": "2018-12-04T02:12:23.878800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (400, 7)\n",
       "  Intercept  gre   gpa  pre1  pre2  pre3  intercept\n",
       "          1  380  3.61     0     0     0          1\n",
       "          1  660  3.67     0     0     0          1\n",
       "          1  800  4.00     0     1     0          1\n",
       "          1  640  3.19     0     0     0          1\n",
       "          1  520  2.93     0     0     0          1\n",
       "          1  760  3.00     1     0     0          1\n",
       "          1  560  2.98     0     1     0          1\n",
       "          1  400  3.08     1     0     0          1\n",
       "          1  540  3.39     0     0     0          1\n",
       "          1  700  3.92     1     0     0          1\n",
       "          1  800  4.00     0     0     0          1\n",
       "          1  440  3.22     0     1     0          1\n",
       "          1  760  4.00     0     1     0          1\n",
       "          1  700  3.08     1     0     0          1\n",
       "          1  700  4.00     0     1     0          1\n",
       "          1  480  3.44     0     0     0          1\n",
       "          1  780  3.87     0     0     0          1\n",
       "          1  360  2.56     0     0     0          1\n",
       "          1  800  3.75     1     0     0          1\n",
       "          1  540  3.81     0     1     0          1\n",
       "          1  500  3.17     0     0     0          1\n",
       "          1  660  3.63     1     0     0          1\n",
       "          1  600  2.82     0     0     0          1\n",
       "          1  680  3.19     0     0     0          1\n",
       "          1  760  3.35     1     0     0          1\n",
       "          1  800  3.66     0     1     0          1\n",
       "          1  620  3.61     0     1     0          1\n",
       "          1  520  3.74     0     0     0          1\n",
       "          1  780  3.22     1     0     0          1\n",
       "          1  520  3.29     0     1     0          1\n",
       "  [370 rows omitted]\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'gre' (column 1)\n",
       "    'gpa' (column 2)\n",
       "    'pre1' (column 3)\n",
       "    'pre2' (column 4)\n",
       "    'pre3' (column 5)\n",
       "    'intercept' (column 6)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import patsy\n",
    "y, X = patsy.dmatrices('admit ~ gre+gpa+pre1+pre2+pre3+intercept', binary)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:12:31.868800Z",
     "start_time": "2018-12-04T02:12:31.822800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   R-squared:                       0.100\n",
      "Model:                            OLS   Adj. R-squared:                  0.091\n",
      "Method:                 Least Squares   F-statistic:                     10.96\n",
      "Date:                Tue, 04 Dec 2018   Prob (F-statistic):           1.95e-08\n",
      "Time:                        10:12:31   Log-Likelihood:                -240.68\n",
      "No. Observations:                 400   AIC:                             491.4\n",
      "Df Residuals:                     395   BIC:                             511.3\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2850      0.103     -2.780      0.006      -0.487      -0.083\n",
      "gre            0.0004      0.000      2.028      0.043    1.31e-05       0.001\n",
      "gpa            0.1586      0.064      2.496      0.013       0.034       0.284\n",
      "pre1           0.1399      0.049      2.861      0.004       0.044       0.236\n",
      "pre2           0.3021      0.066      4.582      0.000       0.172       0.432\n",
      "pre3                0          0        nan        nan           0           0\n",
      "intercept     -0.2850      0.103     -2.780      0.006      -0.487      -0.083\n",
      "==============================================================================\n",
      "Omnibus:                      150.845   Durbin-Watson:                   1.959\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.494\n",
      "Skew:                           0.678   Prob(JB):                     1.08e-11\n",
      "Kurtosis:                       1.908   Cond. No.                     7.71e+34\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.41e-62. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular. [-0.28501762  0.00042687  0.15864152  0.13992809  0.30205197  0.\n",
      " -0.28501762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm    #调用statsmodels里面的api，通过api调用相当于调用了statsmodels.regression.linear_model，可以使用linear_model文件里的函数\n",
    "mod = sm.OLS(y,X)\n",
    "res = mod.fit()\n",
    "print(res.summary(),res.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 复制解释变量X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:12:39.757800Z",
     "start_time": "2018-12-04T02:12:39.727800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DesignMatrix with shape (400, 7)\n",
       "   Intercept  gre   gpa  pre1  pre2  pre3  intercept\n",
       "           1  380  3.61     0     0     0          1\n",
       "           1  660  3.67     0     0     0          1\n",
       "           1  800  4.00     0     1     0          1\n",
       "           1  640  3.19     0     0     0          1\n",
       "           1  520  2.93     0     0     0          1\n",
       "           1  760  3.00     1     0     0          1\n",
       "           1  560  2.98     0     1     0          1\n",
       "           1  400  3.08     1     0     0          1\n",
       "           1  540  3.39     0     0     0          1\n",
       "           1  700  3.92     1     0     0          1\n",
       "           1  800  4.00     0     0     0          1\n",
       "           1  440  3.22     0     1     0          1\n",
       "           1  760  4.00     0     1     0          1\n",
       "           1  700  3.08     1     0     0          1\n",
       "           1  700  4.00     0     1     0          1\n",
       "           1  480  3.44     0     0     0          1\n",
       "           1  780  3.87     0     0     0          1\n",
       "           1  360  2.56     0     0     0          1\n",
       "           1  800  3.75     1     0     0          1\n",
       "           1  540  3.81     0     1     0          1\n",
       "           1  500  3.17     0     0     0          1\n",
       "           1  660  3.63     1     0     0          1\n",
       "           1  600  2.82     0     0     0          1\n",
       "           1  680  3.19     0     0     0          1\n",
       "           1  760  3.35     1     0     0          1\n",
       "           1  800  3.66     0     1     0          1\n",
       "           1  620  3.61     0     1     0          1\n",
       "           1  520  3.74     0     0     0          1\n",
       "           1  780  3.22     1     0     0          1\n",
       "           1  520  3.29     0     1     0          1\n",
       "   [370 rows omitted]\n",
       "   Terms:\n",
       "     'Intercept' (column 0)\n",
       "     'gre' (column 1)\n",
       "     'gpa' (column 2)\n",
       "     'pre1' (column 3)\n",
       "     'pre2' (column 4)\n",
       "     'pre3' (column 5)\n",
       "     'intercept' (column 6)\n",
       "   (to view full data, use np.asarray(this_obj))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop = copy.deepcopy(binary)\n",
    "newX = patsy.build_design_matrices([X.design_info], cop)\n",
    "newX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用newX进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:13:05.947800Z",
     "start_time": "2018-12-04T02:13:05.933800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 47, Hit: 30, Precision: 63.83\n"
     ]
    }
   ],
   "source": [
    "cop['predict'] = res.predict(newX)\n",
    "total = 0\n",
    "hit = 0\n",
    "for value in cop.values:\n",
    "  # 预测分数 predict, 是数据中的最后一列\n",
    "  predict = value[-1]\n",
    "  # 实际录取结果\n",
    "  admit = int(value[0])\n",
    " \n",
    "  # 假定预测概率大于0.5则表示预测被录取\n",
    "  if predict > 0.5:\n",
    "    total += 1\n",
    "    # 表示预测命中\n",
    "    if admit == 1:\n",
    "      hit += 1\n",
    "\n",
    "print ('Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三题："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建，利用LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:23:09.424800Z",
     "start_time": "2018-12-04T02:23:06.339800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method ClassifierMixin.score of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm    #调用statsmodels里面的api，通过api调用相当于调用了statsmodels.regression.linear_model，可以使用linear_model文件里的函数\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mod = LogisticRegression()\n",
    "res = mod.fit(X,y)\n",
    "print(res.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:17:24.677000Z",
     "start_time": "2018-12-03T05:17:24.638000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 37, Hit: 24, Precision: 64.86\n"
     ]
    }
   ],
   "source": [
    "cop['predict'] = res.predict(X)\n",
    "total = 0\n",
    "hit = 0\n",
    "for value in cop.values:\n",
    "  # 预测分数 predict, 是数据中的最后一列\n",
    "  predict = value[-1]\n",
    "  # 实际录取结果\n",
    "  admit = int(value[0])\n",
    "  # 假定预测概率大于0.5则表示预测被录取\n",
    "  if predict > 0.5:\n",
    "    total += 1\n",
    "    # 表示预测命中\n",
    "    if admit == 1:\n",
    "      hit += 1\n",
    "\n",
    "print ('Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:20:45.941000Z",
     "start_time": "2018-12-03T05:20:44.570000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method ClassifierMixin.score of LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)>\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm    #调用statsmodels里面的api，通过api调用相当于调用了statsmodels.regression.linear_model，可以使用linear_model文件里的函数\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "mod = LogisticRegressionCV(10)\n",
    "res = mod.fit(X,y)\n",
    "print(res.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:22:20.405000Z",
     "start_time": "2018-12-03T05:22:20.381000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 48, Hit: 29, Precision: 60.42\n"
     ]
    }
   ],
   "source": [
    "cop['predict'] = res.predict(X)\n",
    "total = 0\n",
    "hit = 0\n",
    "for value in cop.values:\n",
    "  # 预测分数 predict, 是数据中的最后一列\n",
    "  predict = value[-1]\n",
    "  # 实际录取结果\n",
    "  admit = int(value[0])\n",
    "  # 假定预测概率大于0.5则表示预测被录取\n",
    "  if predict > 0.5:\n",
    "    total += 1\n",
    "    # 表示预测命中\n",
    "    if admit == 1:\n",
    "      hit += 1\n",
    "\n",
    "print ('Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用train_test_split分开："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:32:37.430800Z",
     "start_time": "2018-12-04T02:32:37.418800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.33,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:32:39.024800Z",
     "start_time": "2018-12-04T02:32:39.001800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()               \n",
    "model.fit(Xtrain, ytrain)             #训练集\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:32:41.806800Z",
     "start_time": "2018-12-04T02:32:41.788800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 38, Hit: 25, Precision: 65.79\n"
     ]
    }
   ],
   "source": [
    "cop['predict'] = res.predict(X)\n",
    "total = 0\n",
    "hit = 0\n",
    "for value in cop.values:\n",
    "  # 预测分数 predict, 是数据中的最后一列\n",
    "  predict = value[-1]\n",
    "  # 实际录取结果\n",
    "  admit = int(value[0])\n",
    "  # 假定预测概率大于0.5则表示预测被录取\n",
    "  if predict > 0.5:\n",
    "    total += 1\n",
    "    # 表示预测命中\n",
    "    if admit == 1:\n",
    "      hit += 1\n",
    "\n",
    "print ('Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegressionCV训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:32:44.258800Z",
     "start_time": "2018-12-04T02:32:43.783800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method ClassifierMixin.score of LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)>\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm    #调用statsmodels里面的api，通过api调用相当于调用了statsmodels.regression.linear_model，可以使用linear_model文件里的函数\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "mod = LogisticRegressionCV(10)\n",
    "res = mod.fit(Xtrain,ytrain)            #训练集\n",
    "print(res.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T02:33:11.362800Z",
     "start_time": "2018-12-04T02:33:11.345800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 42, Hit: 22, Precision: 52.38\n"
     ]
    }
   ],
   "source": [
    "# 构建预测集\n",
    "# 与训练集相似，一般也是通过 pd.read_csv() 读入\n",
    "# 在这边为方便，我们将训练集拷贝一份作为预测集（不包括 admin 列）\n",
    "cop['predict'] = res.predict(Xtest)\n",
    "total = 0\n",
    "hit = 0\n",
    "for value in cop.values:\n",
    "  # 预测分数 predict, 是数据中的最后一列\n",
    "  predict = value[-1]\n",
    "  # 实际录取结果\n",
    "  admit = int(value[0])\n",
    "  # 假定预测概率大于0.5则表示预测被录取\n",
    "  if predict > 0.5:\n",
    "    total += 1\n",
    "    # 表示预测命中\n",
    "    if admit == 1:\n",
    "      hit += 1\n",
    "\n",
    "# 输出结果\n",
    "print ('Total: %d, Hit: %d, Precision: %.2f' % (total, hit, 100.0*hit/total))\n",
    "# Total: 49, Hit: 30, Precision: 61.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
